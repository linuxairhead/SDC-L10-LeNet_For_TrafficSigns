{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet Lab Solution\n",
    "![LeNet Architecture](lenet.png)\n",
    "Source: Yan LeCun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the MNIST data, which comes pre-loaded with TensorFlow.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "Image Shape: (28, 28, 1)\n",
      "\n",
      "Training Set:    55000 samples\n",
      "Validation Set:  5000 samples\n",
      "Test Set:          10000 samples\n"
     ]
    }
   ],
   "source": [
    "# pre-installed with TensorFlow\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False)\n",
    "# store train set\n",
    "X_train,          y_train           = mnist.train.images,      mnist.train.labels\n",
    "\n",
    "# store validation set\n",
    "X_validation,   y_validation = mnist.validation.images,   mnist.validation.labels\n",
    "\n",
    "# store test set\n",
    "X_test,           y_test             = mnist.test.images,       mnist.test.labels\n",
    "\n",
    "# verify the number of images in each set which is match with labels in each set\n",
    "assert(len(X_train) == len(y_train))\n",
    "assert(len(X_validation) == len(y_validation))\n",
    "assert(len(X_test) == len(y_test))\n",
    "\n",
    "print()\n",
    "# print out shape of first image so we can verify the the demension of the data\n",
    "print(\"Image Shape: {}\".format(X_train[0].shape))   \n",
    "print()\n",
    "\n",
    "# print out size of each set\n",
    "print(\"Training Set:    {} samples\".format(len(X_train)))\n",
    "print(\"Validation Set:  {} samples\".format(len(X_validation)))\n",
    "print(\"Test Set:          {} samples\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data that TensorFlow pre-loads comes as 28x28x1 images.\n",
    "\n",
    "However, the LeNet architecture only accepts 32x32xC images, where C is the number of color channels.\n",
    "\n",
    "In order to reformat the MNIST data into a shape that LeNet will accept, we pad the data with two rows of zeros on the top and bottom, and two columns of zeros on the left and right (28+2+2 = 32).\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Image Shape: (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Pad images with 0s\n",
    "X_train      = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_validation = np.pad(X_validation, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_test       = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    \n",
    "print(\"Updated Image Shape: {}\".format(X_train[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data\n",
    "\n",
    "View a sample from the dataset.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABiFJREFUeJztnF9oFFcUh79jkmqgQVNqgiTSlFAUBTEYymIfLNRADEga\npKU+lFYD+iI0b6150CoIC7Z9MA9VS5QihVJopCJCCdqCUQwakSb+aRJKbY0xEqqsqZq6yenDzqyJ\nu5vd7OzezG7uB8vs7tyZc/a3hzP33jlzRVWxmGHBXDswn7BiG8SKbRArtkGs2AaxYhvEim0QT2KL\nSL2I/C4igyLyWaacylck3UGNiBQA/UAdcAe4DGxV1RuZcy+/KPRw7JvAoKr+ASAi3wONQEKxRSRv\nh6uqKsnaeEkjFcDfUz7fcb6bhojsEJErInLFg628wEtkx/snYyJXVY8CRyG/IzsVvET2HWD5lM+V\nwF1v7uQ3XsS+DLwhIq+LyEvAB8CpzLiVn6SdRlQ1LCK7gJ+BAuCYql7PmGd5SNpdv7SM5XHOznZv\nxDJLrNgGsWIbxIptECu2QazYBrFiG8TL3IgvKCoqYtGiRQDU1tYCsHHjRkQi3d66ujoA1q1bB8DJ\nkyfZv38/AP39/QA8efLEiK85O6hZtWoVAAcPHqS+vj6eLQBm+n1nzpwBYPPmzZ79sYMan5FzkR0I\nBADYt28fEEkZ8Xj48CEAS5YsAeDBgwcAlJaWRtsMDQ0B0NnZCcDu3bu5f/9+Wn7ZyPYZORPZVVVV\nAJw4cQKA9evXx7Tp6+sDIBgM0tvbC8DKlSsBuHXrFgCbNm0iGAzGtbFixQoGBwfT8s9Gts/Iia5f\nRUUFFy9eBKC8vHzavtHRUVpaWgDo6OgAYHx8PLrfjfbi4uJo+7kiJ8QuLi6OEdmlubmZ06dPJzx2\n4cKFALS1tQGwbdu2mDb37t0D4PHjx15dnRGbRgySE5EdjwsXLgBw9uzZuPvdEePx48cBWL16dcJz\nnT9/HoC7d7N7v9pGtkFyNrJramoAaGxsJBwOA1BSUgJEuoVbtmwBYPHixUnPdeTIkSx5OZ2c6GcX\nFhbS2toKwN69e6ftGx8fp7AwEjMFBQVTbQEzz42cO3cOgIaGBgCePXuWjnuuHdvP9hM5kUbC4TAH\nDhwAns9n7NmzB4DKysq4x7jTqGVlZQDs3Lkzps3Tp08BbxE9G2xkGyQnIhtgYmICgPb29mnbZBw6\ndAh4nsNFJJrH3QurKZJGtogsF5FfROSmiFwXkU+c718RkU4RGXC2pcnONd9J2hsRkWXAMlW9KiIl\nQA/wLvAx8I+qBp1HPEpV9dMk5zLW9XGH6ZcuXQJgzZo1MW02bNgAQFdXl2d7qfRGkqYRVR0Ghp33\nj0TkJpGi90bgbafZt8CvwIxim6SpqQmIL/LAwMC0rSlmlbNFpAqoAbqBcuePQFWHRaQswTE7gB3e\n3MwPUhZbRF4GfgRaVDXkXnCSMVdPHiS6XQZw+PBhAEZGRky5A6TY9RORIiJCf6eqHc7XI04+d/N6\nejfv5hFJI1siIdwO3FTVr6bsOgV8BASd7U9Z8TBNtm/fDsQfrru3yEyTShp5C/gQ6BWRa853rURE\n/kFEmoG/gPey42L+kEpvpIv4T4YBvJNZdzJDdXV1wn0DAwN0d3cb9OY5OTOCnA0vzgxOpa2tLVpD\nYho7N2KQnJjPThW3/q+npyc6gnR/3+3bt4HIIGdsbCzjtu18ts/Iq5y9dOlSABYsiI0hd846G1Gd\nMqpq7EXk2fasv+rq6nRyclInJyc1FAppKBTSQCCggUAgazZT+f02jRgkry6Qc4m9QPoMK7ZBrNgG\nsWIbxIptECu2QUyPIEeBf52t33mV1P18LZVGRvvZACJyRVVrjRpNg2z4adOIQazYBpkLsY/Ogc10\nyLifxnP2fMamEYMYE9vPa23PUKn7uYgMicg159XgyY6JNOL3tbZnqNR9HxhT1S8yYcdUZEfX2lbV\n/wB3rW1foKrDqnrVef8IcCt1M4opsVNaa9sPvFCpC7BLRH4TkWNeC/5NiZ3SWttzzYuVusDXQDWw\nlkiN+pdezm9KbN+vtR2vUldVR1R1QlUngW+IpMO0MSW2r9faTlSp65ZEOzQBfV7sGJn1y4G1thNV\n6m4VkbVEUt6fQOzDlLPAjiANYkeQBrFiG8SKbRArtkGs2AaxYhvEim0QK7ZB/gfZaLm7qoIFlQAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ba1b25a710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#select random image from training set\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "# matplotlib to visualize\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "\n",
    "# print out label\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "Shuffle the training data. -- it is important\n",
    "      the ordering of the dat might have a huge effect on how well the network trends\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup TensorFlow\n",
    "The `EPOCH` and `BATCH_SIZE` values affect the training speed and model accuracy.\n",
    "\n",
    "    More Epoch - the better our model will train but also the longer training will take\n",
    "    \n",
    "    Batch size - to tell TensorFlow, how many training images to run through the network at a time    \n",
    "                     larger the batch size faster our model will train, \n",
    "                     but processor may have a memory limit on how large a bach it can run\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLUTION: Implement LeNet-5\n",
    "Implement the [LeNet-5](http://yann.lecun.com/exdb/lenet/) neural network architecture.\n",
    "\n",
    "This is the only cell you need to edit.\n",
    "### Input\n",
    "The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.\n",
    "\n",
    "### Architecture\n",
    "**Layer 1: Convolutional.** The output shape should be 28x28x6.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 14x14x6.\n",
    "\n",
    "**Layer 2: Convolutional.** The output shape should be 10x10x16.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 5x5x16.\n",
    "\n",
    "**Flatten.** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using `tf.contrib.layers.flatten`, which is already imported for you.\n",
    "\n",
    "**Layer 3: Fully Connected.** This should have 120 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 4: Fully Connected.** This should have 84 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 5: Fully Connected (Logits).** This should have 10 outputs.\n",
    "\n",
    "### Output\n",
    "Return the result of the 2nd fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Hyperparameters\n",
    "    #  related to how we initialize our weights\n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # SOLUTION: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "         # this layer has 5x5 filter with an input depth of one and an output depth of six\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma))\n",
    "        # initialize the bias\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "        # use the conv2D function to convolve the filter over the images\n",
    "        # add bias \n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "        # the formula for convolutions tells us that the output height equals the input height minus the filter height plus one all divided by\n",
    "        # the vertical stride.\n",
    "        # input width  =  (32 - 5 +1 )/  1  = 28, output width = 28\n",
    "        \n",
    "                            # so convolutional output layer is 28x28x6\n",
    "        \n",
    "    # SOLUTION: Activation. \n",
    "    # Activated the Convolutional layer with ReLU activation function.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    # pool the output with 2x2 kernel with 2x2 stride\n",
    "    # which gives us a pooling output of 14 x 14 x 6\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # SOLUTION: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b \n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # SOLUTION: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "                       # second convolution output will give 5x5x16    \n",
    "\n",
    "    # SOLUTION: Flatten. Input = 5x5x16. Output = 400.\n",
    "        # flatten output to vector.\n",
    "        # length of the vector is 5x5x16 which is equals to 400\n",
    "    fc0   = flatten(conv2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "        # fully connected layer with a width of 120 \n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # SOLUTION: Activation. ReLU\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "\n",
    "    \n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "        # fully connected layer with a width of 84\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(84))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    \n",
    "    \n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "        #  we attach a fully connected output layer with a width, equal to the number of classes in our label set. \n",
    "        # 10 set, one for each number. \n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 10), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(10))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels\n",
    "Train LeNet to classify [MNIST](http://yann.lecun.com/exdb/mnist/) data.\n",
    "\n",
    "`x` is a placeholder for a batch of input images.\n",
    "`y` is a placeholder for a batch of output labels.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "    # initialized batch size to None, which allows the placeholder to later accept any size of any batch\n",
    "    # we set the image dimensions to 32 by 32 by 1\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "    # y hold the labels which come through with sparse variables, which just means that they are integers\n",
    "one_hot_y = tf.one_hot(y, 10)\n",
    "    # one hot encoded\n",
    "    # tf.one_hot function to one-hot encode the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline\n",
    "Create a training pipeline that uses the model to classify MNIST data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "rate = 0.001\n",
    "    # learning rate tells TensorFlow how quickly to update the networks's weights\n",
    "\n",
    "logits = LeNet(x)\n",
    "    # pass the input data to the LeNet function to calculate our logits\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "    # softmax_cross_entropy_with_logits to compare those logits to the ground truth labes\n",
    "    # and caculate the cross entropy\n",
    "    # cross entropy is just a measure of how different the logits are from the ground truth training labels\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "    # tf.reduce_mean function averages the cross entropy from all of the training images.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "    # AdamOptimizer uses the Adam algorithm to minimize the loss function similarly to what stochastic gradient descent does.\n",
    "    # Adam Algorithm is a little more sophisticated than stochastic gradient descent.\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "    # we run the minimize function on the optimizer which uses backpropagation to update the network \n",
    "    # and minimie our training loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluate how well the loss and accuracy of the model for a given dataset.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "    # to measure whether a given prediction is correct by comparing the logit prediction to the one-hot encoded ground truth label\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    #  calculate the models overall accuracy by averaging the individual prediction accuracies\n",
    "saver = tf.train.Saver()\n",
    "    \n",
    " # data set as input   \n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    \n",
    "    # batches the dataset.\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        \n",
    "        # run through the evaluation pipeline\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        \n",
    "        # averages the accuracy of the each batch to calculate the total accuracy of the model\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Run the training data through the training pipeline to train the model.\n",
    "\n",
    "Before each epoch, shuffle the training set.\n",
    "\n",
    "After each epoch, measure the loss and accuracy of the validation set.\n",
    "\n",
    "Save the model after training.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.959\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.975\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.985\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.986\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.986\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.989\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.986\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.988\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.991\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.987\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# create the TensorFlow session \n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # initialize the vailable.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    \n",
    "    # train over whatever number of epoches has been set in the EPOCHS hyperparameter.\n",
    "    for i in range(EPOCHS):\n",
    "        \n",
    "        # begining of each training, shuffle the data to ensure our training isn't biased by the order of the images\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        \n",
    "        # break training data into batches and train the model on each batch.\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        # evaulate the model on our validation data.    \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "Once you are completely satisfied with your model, evaluate the performance of the model on the test set.\n",
    "\n",
    "Be sure to only do this once!\n",
    "\n",
    "If you were to measure the performance of your trained model on the test set, then improve your model, and then measure the performance of your model on the test set again, that would invalidate your test results. You wouldn't get a true measure of how well your model would perform against real data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
